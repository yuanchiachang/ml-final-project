{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_cuda_setDevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4ea6aaf45f17>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mSEED\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5566\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE_ID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cuda\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Michael\\anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36mset_device\u001b[1;34m(device)\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_device_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cuda_setDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_cuda_setDevice'"
     ]
    }
   ],
   "source": [
    "NUM_EPOCH = 200\n",
    "BATCH_SIZE = 128 \n",
    "LATENT_DIM = 512 \n",
    "REDUCED_DIM = 16 \n",
    "NUM_ITER = 300 \n",
    "MODEL_NAME = 'model.pth'\n",
    "lr = 5e-4\n",
    "\n",
    "DEVICE_ID = 0\n",
    "SEED = 5566\n",
    "\n",
    "torch.cuda.set_device(DEVICE_ID)\n",
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load train data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_label(df, train_dt, label_dt):\n",
    "    train_dt = [\"dt%d\" % i for i in train_dt]\n",
    "    label_dt = [\"dt%d\" % (label_dt - 1), \"dt%d\" % (label_dt)]\n",
    "    label = df[label_dt].values.tolist()\n",
    "    idx = df['chid'].tolist()\n",
    "    tag_feat = df[train_dt].values.tolist()\n",
    "    for i in range(len(tag_feat)):\n",
    "        tag_feat[i] = np.array([ast.literal_eval(x) for x in tag_feat[i]])\n",
    "    for j in range(len(label)):\n",
    "        label[j][1] = np.array(ast.literal_eval(label[j][1]))\n",
    "    return idx, tag_feat, [i[1] for i in label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alldt = pd.read_csv(\"./data/dt_all.csv\")\n",
    "train_idx, train_tag, train_label = load_train_label(df_alldt, [1,2,3,4,5,6,7,8,9,10], 11) #dt=1~10 as input feature, dt=11 as label\n",
    "train_idx, valid_idx, train_label_tag, valid_label_tag, train_label, valid_label = train_test_split(train_idx, train_tag, train_label, test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, id_list, tag, labels):\n",
    "        self.id_list = id_list\n",
    "        self.tag = tag\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.id_list[idx], self.tag[idx], self.labels[idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = LSTM_Dataset(train_idx, train_label_tag, train_label), LSTM_Dataset(valid_idx, valid_label_tag, valid_label)\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                            batch_size = 128,\n",
    "                                            shuffle = True)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset = valid_dataset,\n",
    "                                            batch_size = 128,\n",
    "                                            shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Backbone(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, num_layers, bidirectional, fix_embedding=True):\n",
    "        super(LSTM_Backbone, self).__init__()\n",
    "        #self.dropout = torch.nn.Dropout(p=0.75) if not (fix_embedding) else torch.nn.Dropout(p=0)\n",
    "        self.lstm = torch.nn.LSTM(16, hidden_dim, num_layers=num_layers, \\\n",
    "                                  bidirectional=bidirectional, batch_first=True, dropout = 0.55)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        #inputs = self.dropout(inputs)\n",
    "        x, _ = self.lstm(inputs)\n",
    "        return x\n",
    "    \n",
    "class Header(torch.nn.Module):\n",
    "    def __init__(self, dropout, hidden_dim):\n",
    "        super(Header, self).__init__()\n",
    "        self.classifier = torch.nn.Sequential(torch.nn.Dropout(dropout),\n",
    "                                  torch.nn.Linear(hidden_dim, 16),\n",
    "                                  torch.nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # the input shape should be (N, L, Dâˆ—H)\n",
    "        inputs = inputs.sum(dim=1)\n",
    "        out = self.classifier(inputs)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, backbone, header, optimizer, criterion, device, epoch):\n",
    "\n",
    "    total_loss = []\n",
    "    total_acc = []\n",
    "\n",
    "    for idx, (idx, tags, labels) in enumerate(train_loader):\n",
    "        tags, labels = tags.float().to(device), labels.float().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        if not backbone is None:\n",
    "            inputs = backbone(tags)\n",
    "        soft_predicted = header(inputs)\n",
    "        loss = criterion(soft_predicted, labels)\n",
    "        total_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #with torch.no_grad():\n",
    "        '''\n",
    "        hard_predicted = (soft_predicted >= 0.5).int()\n",
    "        correct = sum(hard_predicted == labels).item()\n",
    "        batch_size = len(labels)\n",
    "        acc = correct * 100 / batch_size\n",
    "        total_acc.append(acc)\n",
    "        '''\n",
    "        #print('[ Epoch {}: {}/{} ] loss:{:.3f} '.format(epoch+1, i+1, len(train_loader), loss.item()))\n",
    "    return np.mean(total_loss)\n",
    "def valid(valid_loader, backbone, header, criterion, device, epoch):\n",
    "    backbone.eval()\n",
    "    header.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = []\n",
    "        #total_acc = []\n",
    "        \n",
    "        for idx, (idx, tags, labels) in enumerate(train_loader):\n",
    "            #print(tags[0])\n",
    "            #print(labels[0])\n",
    "            tags, labels = tags.float().to(device), labels.float().to(device)\n",
    "\n",
    "            if not backbone is None:\n",
    "                inputs = backbone(tags)\n",
    "            soft_predicted = header(inputs)\n",
    "            loss = criterion(soft_predicted, labels)\n",
    "            total_loss.append(loss.item())\n",
    "            '''\n",
    "            hard_predicted = (soft_predicted >= 0.5).int()\n",
    "            correct = sum(hard_predicted == labels).item()\n",
    "            acc = correct * 100 / len(labels)\n",
    "            total_acc.append(acc)\n",
    "            \n",
    "            print('[Validation in epoch {:}] loss:{:.3f} acc:{:.3f}'.format(epoch+1, np.mean(total_loss), np.mean(total_acc)), end='\\r')\n",
    "            '''\n",
    "    backbone.train()\n",
    "    header.train()\n",
    "    return np.mean(total_loss)\n",
    "\n",
    "            \n",
    "def run_training(train_loader, valid_loader, backbone, header, epoch_num, lr, device):\n",
    "    total_acc =[] \n",
    "    global patience\n",
    "    patience = 0\n",
    "    def is_stop(loss, acc):\n",
    "        global patience\n",
    "        if (acc < max(total_acc)):\n",
    "          patience += 1\n",
    "        else:\n",
    "          patience = 0\n",
    "        if (patience > 12):\n",
    "          return True\n",
    "        else:\n",
    "          return False\n",
    "    \n",
    "    if backbone is None:\n",
    "        trainable_paras = header.parameters()\n",
    "    else:\n",
    "        trainable_paras = list(backbone.parameters()) + list(header.parameters())\n",
    "        \n",
    "    optimizer = torch.optim.Adam(trainable_paras, lr=1e-5)\n",
    "    \n",
    "    backbone.train()\n",
    "    header.train()\n",
    "    backbone = backbone.to(device)\n",
    "    header = header.to(device)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    for epoch in range(epoch_num):\n",
    "        loss_t = train(train_loader, backbone, header, optimizer, criterion, device, epoch)\n",
    "        loss = valid(valid_loader, backbone, header, criterion, device, epoch)\n",
    "        print('[Training in epoch {:}] loss:{:.3f}'.format(epoch+1, loss_t))\n",
    "        print('[Validation in epoch {:}] loss:{:.3f}'.format(epoch+1, loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_testing(test_loader, backbone, header, device, output_path):\n",
    "    with open(output_path, 'w', newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['chid', 'top1', 'top2', 'top3'])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for idx, (idx, tags, labels) in enumerate(test_loader):\n",
    "                #print(tags[0])\n",
    "                #print(labels[0])\n",
    "                tags, labels = tags.float().to(device), labels.float().to(device)\n",
    "                #print(tags[0:4])\n",
    "                if not backbone is None:\n",
    "                    inputs = backbone(tags)\n",
    "                #print(inputs[0:4])\n",
    "                soft_predicted = header(inputs)\n",
    "                soft_predicted = soft_predicted.detach().cpu().numpy()\n",
    "                #print(soft_predicted[0:4])\n",
    "                \n",
    "                pred1 = []\n",
    "                pred2 = []\n",
    "                pred3 = []\n",
    "                tag_list = [\"2\",\"6\",\"10\",\"12\",\"13\",\"15\",\"18\",\"19\",\"21\",\"22\",\"25\",\"26\",\"36\",\"37\",\"39\",\"48\"]\n",
    "                for i in range(len(idx)):\n",
    "                    #print(soft_predicted[i])\n",
    "                    res = np.argpartition(soft_predicted[i], -3)[-3:]\n",
    "                    #print(res)\n",
    "                    pred1.append(tag_list[res[0]])\n",
    "                    pred2.append(tag_list[res[1]])\n",
    "                    pred3.append(tag_list[res[2]])\n",
    "                #print(pred1, pred2, pred3)\n",
    "                for i, p1, p2, p3 in zip(idx, pred1, pred2, pred3):\n",
    "                    writer.writerow([str(i.item()), str(p3), str(p2), str(p1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = LSTM_Backbone(hidden_dim=256, num_layers=4, bidirectional=True)\n",
    "header = Header(dropout=0, hidden_dim=512)\n",
    "run_training(train_loader, valid_loader, backbone, header, 100, lr, device)\n",
    "torch.save({'backbone': backbone.state_dict(), 'header': header.state_dict()}, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run testing (dt_all.csv, dt_10to22.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alldt = pd.read_csv(\"./data/dt_all.csv\")\n",
    "test_idx, test_tag, test_label = load_train_label(df_alldt, [14,15,16,17,18,19,20,21,22,23], 23)\n",
    "test_dataset = LSTM_Dataset(test_idx, test_tag, test_label)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = 128,\n",
    "                                            shuffle = False)\n",
    "run_testing(test_loader, backbone, header, device, \"result_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10to22 = pd.read_csv(\"./data/dt_10to22_post.csv\")\n",
    "test_idx, test_tag, test_label = load_train_label(df_10to22, [14,15,16,17,18,19,20,21,22,23], 23)\n",
    "test_dataset = LSTM_Dataset(test_idx, test_tag, test_label)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = 128,\n",
    "                                            shuffle = False)\n",
    "run_testing(test_loader, backbone, header, device, \"result_10to22.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"./data/dt_all.csv\")\n",
    "test_idx, test_tag, test_label = load_train_label(df_all, [14,15,16,17,18,19,20,21,22,23], 23)\n",
    "test_dataset = LSTM_Dataset(test_idx, test_tag, test_label)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                            batch_size = 128,\n",
    "                                            shuffle = False)\n",
    "run_testing(test_loader, backbone, header, device, \"result_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dfd08cca5e653bd6ce7f5e5fbd17cf713840c7479c8a6349f69f4f345602522d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
