{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the large training data to several smaller csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來源： 玉山比賽 slack 群組官方問答區 channel 陳淳澐於 2021/11/23 提供 pandasDATAchunk.py 檔案修改而成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reader_pandas_datacount(file, chunkSize):\n",
    "    reader = pd.read_csv(file, chunksize=chunkSize)\n",
    "    \n",
    "    totalData=0\n",
    "    for chunk in reader:\n",
    "        chunkData_total = chunk.shape\n",
    "        patitions = chunkData_total[0]\n",
    "        \n",
    "        with tqdm(range(patitions), 'Reading......') as t:\n",
    "            for _ in t:\n",
    "                try:\n",
    "                    totalData = totalData + 1       \n",
    "                    \n",
    "                except StopIteration:\n",
    "                        break\n",
    "        print(\"\\nchunk : \" + str(totalData))\n",
    "        print(\"data count : \" + str(totalData*chunkSize))\n",
    "                \n",
    "    print(\"料估計完畢\")\n",
    "    print(\"總共 \" + str(totalData*chunkSize) + \" 筆資料\")\n",
    "    input(\"請按 Enter 繼續\")\n",
    "    return chunkSize, totalData\n",
    "\n",
    "# Progressbar進度讀取條功能，此為個人修改後的版本 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Myreader_pandas(file, chunkSize, memoryflag=False):\n",
    "    \n",
    "    print(\"資料估計中......\")\n",
    "    chunkSize, patitions_total = reader_pandas_datacount(file,chunkSize)\n",
    "    \n",
    "    print(\"資料讀取中......\")\n",
    "    reader = pd.read_csv(file, iterator=True)\n",
    "    chunks = []     \n",
    "    \n",
    "    j_No=0\n",
    "    with tqdm(range(patitions_total), 'Reading......') as t:\n",
    "        for _ in t:\n",
    "            try:\n",
    "                chunk = reader.get_chunk(chunkSize)\n",
    "                #chunks.append(chunk)                \n",
    "                #df_feature = pd.concat(chunks, ignore_index=True)\n",
    "                #df_feature = pd.concat(chunk, ignore_index=True)\n",
    "        \n",
    "                if memoryflag == False:\n",
    "                    # 建立存檔用料夾(名稱: 變數FolderName)\n",
    "                    FolderName = \"Tbrain_splitData\"\n",
    "                    savefileFolderPath = os.path.join(\"./\",FolderName)\n",
    "                \n",
    "                    if not os.path.exists(savefileFolderPath):\n",
    "                        os.mkdir(savefileFolderPath)\n",
    "                    \n",
    "                    # 存檔: .csv檔     \n",
    "                    fileName = \"tbrain_cc_SplitTraining_data_part\" + str(j_No) + \".csv\"            \n",
    "                    savefilePath = os.path.join(savefileFolderPath,fileName)                \n",
    "                \n",
    "                    #df_feature.to_csv(savefilePath, mode='a')\n",
    "                    chunk.to_csv(savefilePath, mode='a')\n",
    "                j_No = j_No + 1        \n",
    "            except StopIteration:\n",
    "                break    \n",
    "            \n",
    "    return pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUNfilePath = os.path.join(\"../../\",\"train\")\n",
    "DatafileName = \"train.csv\"\n",
    "openfilePath = os.path.join(RUNfilePath,DatafileName)\n",
    "\n",
    "# 資料拆分流程 #\n",
    "# 讀取資料集，很大所以用chunkSize加速讀取時間    \n",
    "tmp = Myreader_pandas(openfilePath, 100000)\n",
    "tmp.info()\n",
    "##tmp = Myreader_pandas(openfilePath, 100000,True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
