{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import csv\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRA_PATH = './data/full_reduced_train.csv'\n",
    "TST_PATH = './data/not_full_reduced_train.csv'\n",
    "LABEL_PATH = './data/full_record.csv'\n",
    "DEVICE_ID = 2\n",
    "SEED = 5566\n",
    "NUM_ECPOCH = 3\n",
    "transform = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## device config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_gpu else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(train_path, label_path, valid_ratio=0.12):\n",
    "    train_label_original = pd.read_csv(label_path)['top1'].values.tolist()\n",
    "    category = [2, 6, 10, 12, 13, 15, 18, 19, 21, 22, 25, 26, 36, 37, 39, 48]\n",
    "    train_label = np.zeros(len(train_label_original))\n",
    "    for i in range(len(train_label_original)):\n",
    "        for j in range(len(category)):\n",
    "            if(train_label_original[i] == category[j]):\n",
    "                train_label[i] = j\n",
    "    df = pd.read_csv(train_path)\n",
    "    train_predict = df[[\"masts\",\"educd\",\"trdtp\",\"naty\",\"poscd\",\"cuorg\",\"slam\",\"gender_code\",\"age\"]].to_numpy()\n",
    "    mean = np.mean(train_predict, axis=0)\n",
    "    std = np.std(train_predict, axis=0)\n",
    "    for i in range(len(train_predict)):\n",
    "        train_predict[i] = (train_predict[i] - mean) / std\n",
    "    train_data = list(zip(train_predict, train_label))\n",
    "    random.shuffle(train_data)\n",
    "    \n",
    "    split_len = int(len(train_data) * valid_ratio)\n",
    "    train_set = train_data[split_len:]\n",
    "    valid_set = train_data[:split_len]\n",
    "    \n",
    "    return train_set, valid_set\n",
    "\n",
    "def load_test_data(test_path):\n",
    "    df = pd.read_csv(test_path)\n",
    "    test_set = df[[\"masts\",\"educd\",\"trdtp\",\"naty\",\"poscd\",\"cuorg\",\"slam\",\"gender_code\",\"age\"]].to_numpy()\n",
    "    mean = np.mean(test_set, axis=0)\n",
    "    std = np.std(test_set, axis=0)\n",
    "    for i in range(len(test_set)):\n",
    "        test_set[i] = (test_set[i] - mean) / std\n",
    "    return test_set\n",
    "\n",
    "train_set, valid_set = load_train_data(TRA_PATH, LABEL_PATH)\n",
    "test_set = load_test_data(TST_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceExpressionDataset(Dataset):\n",
    "    def __init__(self, data, augment=None):\n",
    "        self.data = data\n",
    "        self.augment = augment\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.data[idx][1]\n",
    "        return self.data[idx][0], label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestingDataset(Dataset):\n",
    "    def __init__(self, data, augment=None):\n",
    "        self.data = data\n",
    "        self.augment = augment      \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "      \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input train set and data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FaceExpressionDataset(train_set, transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "valid_dataset = FaceExpressionDataset(valid_set, transform)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "test_dataset = TestingDataset(test_set,transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceExpressionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceExpressionNet, self).__init__()\n",
    "        # TODO    \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(9, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,64),\n",
    "            nn.ReLU(),\n",
    "            torch.nn.Dropout(0.5),\n",
    "            nn.Linear(64, 16)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, loss_fn, use_gpu=True):\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    for (data, label) in train_loader:\n",
    "        if use_gpu:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        data = torch.tensor(data, dtype=torch.float32)\n",
    "        label= torch.tensor(label, dtype=torch.long)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, label)\n",
    "        loss.backward()            \n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            predict = torch.argmax(output, dim=-1)\n",
    "            acc = np.mean((label == predict).cpu().numpy())\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss.item())\n",
    "    print(\"Epoch: {}, train Loss: {:.4f}, train Acc: {:.4f}\".format(epoch + 1, np.mean(train_loss), np.mean(train_acc)))\n",
    "    \n",
    "def valid(valid_loader, model, loss_fn, use_gpu=True):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = []\n",
    "        valid_acc = []\n",
    "        for idx, (data, label) in enumerate(valid_loader):\n",
    "            if use_gpu:\n",
    "                data = data.to(device)\n",
    "                label = label.to(device)\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "            label= torch.tensor(label, dtype=torch.long)\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, label)\n",
    "            \n",
    "            \n",
    "            predict = torch.argmax(output, dim=-1)\n",
    "            acc = (label == predict).cpu().tolist()\n",
    "            valid_loss.append(loss.item())\n",
    "            valid_acc += acc\n",
    "       \n",
    "        valid_acc = np.mean(valid_acc)\n",
    "        valid_loss = np.mean(valid_loss)\n",
    "        print(\"Epoch: {}, valid Loss: {:.4f}, valid Acc: {:.4f}\".format(epoch + 1, valid_loss, valid_acc))\n",
    "    return valid_acc\n",
    "\n",
    "def save_checkpoint(valid_acc, acc_record, epoch, prefix='model'):\n",
    "#     you can define the condition to save model :)\n",
    "    if valid_acc >= np.mean(acc_record[-5:]):    \n",
    "        checkpoint_path = f'{prefix}.pth'\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print('model saved to %s' % checkpoint_path)\n",
    "\n",
    "def early_stop(valid_acc):\n",
    "    # TODO\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FaceExpressionNet()\n",
    "if use_gpu:\n",
    "    model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "acc_record = []\n",
    "for epoch in range(NUM_ECPOCH):\n",
    "    train(train_loader, model, loss_fn, use_gpu)\n",
    "    valid_acc = valid(valid_loader, model, loss_fn, use_gpu=True)\n",
    "    acc_record.append(valid_acc)\n",
    "\n",
    "    save_checkpoint(valid_acc, acc_record, epoch, prefix='model')\n",
    "    if early_stop(valid_acc):\n",
    "        break\n",
    "\n",
    "    print('########################################################')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, file_name='./data/predict_not_full.csv'):\n",
    "    with torch.no_grad():\n",
    "        predict_result = np.zeros((0,3))\n",
    "        for idx, data in enumerate(test_loader):\n",
    "            if use_gpu:\n",
    "                data = data.to(device)\n",
    "            data = torch.tensor(data, dtype=torch.float32)\n",
    "            output = model(data)\n",
    "            output_sort = np.argsort(output)\n",
    "            output_top3 = output_sort[:,(-1,-2,-3)].numpy()\n",
    "            predict_result = np.concatenate((predict_result, output_top3), axis=0)\n",
    "\n",
    "    with open(file_name, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow(['chid', 'top1','top2','top3'])\n",
    "        test_df = pd.read_csv(TST_PATH)\n",
    "        category = [2, 6, 10, 12, 13, 15, 18, 19, 21, 22, 25, 26, 36, 37, 39, 48]\n",
    "        for i in range(len(predict_result)):\n",
    "            writer.writerow([test_df['chid'][i], str(category[int(predict_result[i][0])]),\n",
    "                             str(category[int(predict_result[i][1])]), str(category[int(predict_result[i][2])])])\n",
    "\n",
    "test(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
